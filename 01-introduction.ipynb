{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Jupyter Notebooks\n",
    "\n",
    "Welcome to your first Jupyter notebook! We will be using notebooks like these throughout the course to teach you concepts in data science and machine learning. Jupyter notebooks are like interactive coding worksheets; you can create __text blocks__ (like this one) and __code blocks__ (like the one below). Text blocks use [Markdown](https://daringfireball.net/projects/markdown/), a simple language for creating rich text, which also supports inline HTML. Code blocks contain code which can be run, and the output of a code block is saved even after you close the notebook. The programming language used in the code block depends on the __kernel__ that you select; for this course you should always use the custom Python kernel that you created from your Anaconda environment.\n",
    "\n",
    "Check out the \"Help\" menu to learn more about how to use Jupyter notebooks. For now, make sure your Anaconda environment is working by running this Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If your Anaconda environment is set up correctly and all of these packages are installed, you should see nothing as the output. Additionally, if you installed `tensorflow-gpu` then you must run this notebook on a machine with an NVIDIA GPU for the `tensorflow` module to import correctly.\n",
    "\n",
    "One really useful feature to know with Python is the `help()` function. You can call `help()` on just about anything, including modules and functions. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn\n",
      "\n",
      "DESCRIPTION\n",
      "    Machine learning module for Python\n",
      "    ==================================\n",
      "    \n",
      "    sklearn is a Python module integrating classical machine\n",
      "    learning algorithms in the tightly-knit world of scientific Python\n",
      "    packages (numpy, scipy, matplotlib).\n",
      "    \n",
      "    It aims to provide simple and efficient solutions to learning problems\n",
      "    that are accessible to everybody and reusable in various contexts:\n",
      "    machine-learning as a versatile tool for science and engineering.\n",
      "    \n",
      "    See http://scikit-learn.org for complete documentation.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __check_build (package)\n",
      "    _build_utils (package)\n",
      "    _config\n",
      "    _isotonic\n",
      "    base\n",
      "    calibration\n",
      "    cluster (package)\n",
      "    compose (package)\n",
      "    covariance (package)\n",
      "    cross_decomposition (package)\n",
      "    datasets (package)\n",
      "    decomposition (package)\n",
      "    discriminant_analysis\n",
      "    dummy\n",
      "    ensemble (package)\n",
      "    exceptions\n",
      "    externals (package)\n",
      "    feature_extraction (package)\n",
      "    feature_selection (package)\n",
      "    gaussian_process (package)\n",
      "    impute\n",
      "    isotonic\n",
      "    kernel_approximation\n",
      "    kernel_ridge\n",
      "    linear_model (package)\n",
      "    manifold (package)\n",
      "    metrics (package)\n",
      "    mixture (package)\n",
      "    model_selection (package)\n",
      "    multiclass\n",
      "    multioutput\n",
      "    naive_bayes\n",
      "    neighbors (package)\n",
      "    neural_network (package)\n",
      "    pipeline\n",
      "    preprocessing (package)\n",
      "    random_projection\n",
      "    semi_supervised (package)\n",
      "    setup\n",
      "    svm (package)\n",
      "    tests (package)\n",
      "    tree (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clone(estimator, safe=True)\n",
      "        Constructs a new estimator with the same parameters.\n",
      "        \n",
      "        Clone does a deep copy of the model in an estimator\n",
      "        without actually copying attached data. It yields a new estimator\n",
      "        with the same parameters that has not been fit on any data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object, or list, tuple or set of objects\n",
      "            The estimator or group of estimators to be cloned\n",
      "        \n",
      "        safe : boolean, optional\n",
      "            If safe is false, clone will fall back to a deep copy on objects\n",
      "            that are not estimators.\n",
      "    \n",
      "    config_context(**new_config)\n",
      "        Context manager for global scikit-learn configuration\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, optional\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error.  Global default: False.\n",
      "        \n",
      "        working_memory : int, optional\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. Global default: 1024.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All settings, not just those presently modified, will be returned to\n",
      "        their previous values when the context manager is exited. This is not\n",
      "        thread-safe.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import sklearn\n",
      "        >>> from sklearn.utils.validation import assert_all_finite\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     assert_all_finite([float('nan')])\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     with sklearn.config_context(assume_finite=False):\n",
      "        ...         assert_all_finite([float('nan')])\n",
      "        ... # doctest: +ELLIPSIS\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Input contains NaN, ...\n",
      "    \n",
      "    get_config()\n",
      "        Retrieve current values for configuration set by :func:`set_config`\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        config : dict\n",
      "            Keys are parameter names that can be passed to :func:`set_config`.\n",
      "    \n",
      "    set_config(assume_finite=None, working_memory=None)\n",
      "        Set global scikit-learn configuration\n",
      "        \n",
      "        .. versionadded:: 0.19\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, optional\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error.  Global default: False.\n",
      "        \n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        working_memory : int, optional\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. Global default: 1024.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    show_versions()\n",
      "        Print useful debugging information\n",
      "\n",
      "DATA\n",
      "    __SKLEARN_SETUP__ = False\n",
      "    __all__ = ['calibration', 'cluster', 'covariance', 'cross_decompositio...\n",
      "\n",
      "VERSION\n",
      "    0.20.2\n",
      "\n",
      "FILE\n",
      "    /home/ppatel2/.conda/envs/myenv/lib/python3.6/site-packages/sklearn/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function randn:\n",
      "\n",
      "randn(...) method of mtrand.RandomState instance\n",
      "    randn(d0, d1, ..., dn)\n",
      "    \n",
      "    Return a sample (or samples) from the \"standard normal\" distribution.\n",
      "    \n",
      "    If positive, int_like or int-convertible arguments are provided,\n",
      "    `randn` generates an array of shape ``(d0, d1, ..., dn)``, filled\n",
      "    with random floats sampled from a univariate \"normal\" (Gaussian)\n",
      "    distribution of mean 0 and variance 1 (if any of the :math:`d_i` are\n",
      "    floats, they are first converted to integers by truncation). A single\n",
      "    float randomly sampled from the distribution is returned if no\n",
      "    argument is provided.\n",
      "    \n",
      "    This is a convenience function.  If you want an interface that takes a\n",
      "    tuple as the first argument, use `numpy.random.standard_normal` instead.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    d0, d1, ..., dn : int, optional\n",
      "        The dimensions of the returned array, should be all positive.\n",
      "        If no argument is given a single Python float is returned.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Z : ndarray or float\n",
      "        A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\n",
      "        the standard normal distribution, or a single such float if\n",
      "        no parameters were supplied.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    standard_normal : Similar, but takes a tuple as its argument.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    For random samples from :math:`N(\\mu, \\sigma^2)`, use:\n",
      "    \n",
      "    ``sigma * np.random.randn(...) + mu``\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.random.randn()\n",
      "    2.1923875335537315 #random\n",
      "    \n",
      "    Two-by-four array of samples from N(3, 6.25):\n",
      "    \n",
      "    >>> 2.5 * np.random.randn(2, 4) + 3\n",
      "    array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],  #random\n",
      "           [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]]) #random\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.random.randn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can also run shell commands from the notebook with the `!` prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ppatel2/Dropbox/Deep Learning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That way you don't have to switch to a terminal window to check on things from the command-line."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
